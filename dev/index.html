<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · ErrorMetrics.jl</title><meta name="title" content="Home · ErrorMetrics.jl"/><meta property="og:title" content="Home · ErrorMetrics.jl"/><meta property="twitter:title" content="Home · ErrorMetrics.jl"/><meta name="description" content="Documentation for ErrorMetrics.jl."/><meta property="og:description" content="Documentation for ErrorMetrics.jl."/><meta property="twitter:description" content="Documentation for ErrorMetrics.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>ErrorMetrics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Quick-start"><span>Quick start</span></a></li><li><a class="tocitem" href="#Available-Metrics"><span>Available Metrics</span></a></li><li><a class="tocitem" href="#Adding-a-New-Metric"><span>Adding a New Metric</span></a></li><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li><li><a class="tocitem" href="#Best-Practices"><span>Best Practices</span></a></li><li><a class="tocitem" href="#Defining-Purpose-for-Metric-Types"><span>Defining Purpose for Metric Types</span></a></li></ul></li><li><a class="tocitem" href="types/">Types</a></li><li><a class="tocitem" href="api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/LandEcosystems/ErrorMetrics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/LandEcosystems/ErrorMetrics.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="ErrorMetrics.jl"><a class="docs-heading-anchor" href="#ErrorMetrics.jl">ErrorMetrics.jl</a><a id="ErrorMetrics.jl-1"></a><a class="docs-heading-anchor-permalink" href="#ErrorMetrics.jl" title="Permalink"></a></h1><p>A Julia package providing error / performance metrics for comparing model outputs with observations.</p><h2 id="Quick-start"><a class="docs-heading-anchor" href="#Quick-start">Quick start</a><a id="Quick-start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-start" title="Permalink"></a></h2><pre><code class="language-julia hljs">using ErrorMetrics

y  = randn(100)             # observations
ŷ  = y .+ 0.1randn(100)     # model output

mse  = metric(MSE(),  ŷ, y)
nse  = metric(NSE(),  ŷ, y)
pcor = metric(Pcor(), ŷ, y)

# with observational uncertainty
yσ = 0.2 .* ones(100)
nseσ = metric(NSEσ(), ŷ, y, yσ)</code></pre><p>See the <a href="api/">API</a> page for the full list of metrics.</p><h2 id="Available-Metrics"><a class="docs-heading-anchor" href="#Available-Metrics">Available Metrics</a><a id="Available-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Available-Metrics" title="Permalink"></a></h2><h3 id="Error-based-Metrics"><a class="docs-heading-anchor" href="#Error-based-Metrics">Error-based Metrics</a><a id="Error-based-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Error-based-Metrics" title="Permalink"></a></h3><ul><li><code>MSE</code>: Mean squared error - Measures the average squared difference between predicted and observed values</li><li><code>NAME1R</code>: Normalized Absolute Mean Error with 1/R scaling - Measures the absolute difference between means normalized by the range of observations</li><li><code>NMAE1R</code>: Normalized Mean Absolute Error with 1/R scaling - Measures the average absolute error normalized by the range of observations</li></ul><h3 id="Nash-Sutcliffe-Efficiency-Metrics"><a class="docs-heading-anchor" href="#Nash-Sutcliffe-Efficiency-Metrics">Nash-Sutcliffe Efficiency Metrics</a><a id="Nash-Sutcliffe-Efficiency-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Nash-Sutcliffe-Efficiency-Metrics" title="Permalink"></a></h3><ul><li><code>NSE</code>: Nash-Sutcliffe Efficiency - Measures model performance relative to the mean of observations</li><li><code>NSEInv</code>: Inverse Nash-Sutcliffe Efficiency - Inverse of NSE for minimization problems</li><li><code>NSEσ</code>: Nash-Sutcliffe Efficiency with uncertainty - Incorporates observation uncertainty in the performance measure</li><li><code>NSEσInv</code>: Inverse Nash-Sutcliffe Efficiency with uncertainty - Inverse of NSEσ for minimization problems</li><li><code>NNSE</code>: Normalized Nash-Sutcliffe Efficiency - Measures model performance relative to the mean of observations, normalized to [0,1] range</li><li><code>NNSEInv</code>: Inverse Normalized Nash-Sutcliffe Efficiency - Inverse of NNSE for minimization problems, normalized to [0,1] range</li><li><code>NNSEσ</code>: Normalized Nash-Sutcliffe Efficiency with uncertainty - Incorporates observation uncertainty in the normalized performance measure</li><li><code>NNSEσInv</code>: Inverse Normalized Nash-Sutcliffe Efficiency with uncertainty - Inverse of NNSEσ for minimization problems</li></ul><h3 id="Correlation-based-Metrics"><a class="docs-heading-anchor" href="#Correlation-based-Metrics">Correlation-based Metrics</a><a id="Correlation-based-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Correlation-based-Metrics" title="Permalink"></a></h3><ul><li><code>Pcor</code>: Pearson Correlation - Measures linear correlation between predictions and observations</li><li><code>PcorInv</code>: Inverse Pearson Correlation - Inverse of Pcor for minimization problems</li><li><code>Pcor2</code>: Squared Pearson Correlation - Measures the strength of linear relationship between predictions and observations</li><li><code>Pcor2Inv</code>: Inverse Squared Pearson Correlation - Inverse of Pcor2 for minimization problems</li><li><code>NPcor</code>: Normalized Pearson Correlation - Measures linear correlation between predictions and observations, normalized to [0,1] range</li><li><code>NPcorInv</code>: Inverse Normalized Pearson Correlation - Inverse of NPcor for minimization problems</li></ul><h3 id="Rank-Correlation-Metrics"><a class="docs-heading-anchor" href="#Rank-Correlation-Metrics">Rank Correlation Metrics</a><a id="Rank-Correlation-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Rank-Correlation-Metrics" title="Permalink"></a></h3><ul><li><code>Scor</code>: Spearman Correlation - Measures monotonic relationship between predictions and observations</li><li><code>ScorInv</code>: Inverse Spearman Correlation - Inverse of Scor for minimization problems</li><li><code>Scor2</code>: Squared Spearman Correlation - Measures the strength of monotonic relationship between predictions and observations</li><li><code>Scor2Inv</code>: Inverse Squared Spearman Correlation - Inverse of Scor2 for minimization problems</li><li><code>NScor</code>: Normalized Spearman Correlation - Measures monotonic relationship between predictions and observations, normalized to [0,1] range</li><li><code>NScorInv</code>: Inverse Normalized Spearman Correlation - Inverse of NScor for minimization problems</li></ul><h2 id="Adding-a-New-Metric"><a class="docs-heading-anchor" href="#Adding-a-New-Metric">Adding a New Metric</a><a id="Adding-a-New-Metric-1"></a><a class="docs-heading-anchor-permalink" href="#Adding-a-New-Metric" title="Permalink"></a></h2><h3 id="1.-Define-the-Metric-Type"><a class="docs-heading-anchor" href="#1.-Define-the-Metric-Type">1. Define the Metric Type</a><a id="1.-Define-the-Metric-Type-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Define-the-Metric-Type" title="Permalink"></a></h3><p>Create a new metric type in the ErrorMetrics.jl source:</p><pre><code class="language-julia hljs">export NewMetric
struct NewMetric &lt;: ErrorMetric end</code></pre><p>Requirements:</p><ul><li>Use PascalCase for the type name</li><li>Make it a subtype of <code>ErrorMetric</code></li><li>Export the type</li><li>Add a purpose function describing the metric&#39;s role</li></ul><h3 id="2.-Implement-the-Metric-Function"><a class="docs-heading-anchor" href="#2.-Implement-the-Metric-Function">2. Implement the Metric Function</a><a id="2.-Implement-the-Metric-Function-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Implement-the-Metric-Function" title="Permalink"></a></h3><p>Implement the metric calculation:</p><pre><code class="language-julia hljs">function metric(::NewMetric, ŷ::AbstractArray, y::AbstractArray, yσ::AbstractArray)
    # Your metric calculation here
    return metric_value
end</code></pre><p>Requirements:</p><ul><li>Function must be named <code>metric</code></li><li>Must take four arguments:<ul><li><code>ŷ</code>: Model simulation data/estimate</li><li><code>y</code>: Observation data</li><li><code>yσ</code>: Observational uncertainty data</li><li>The metric type</li></ul></li><li>Must return a scalar value</li></ul><h3 id="3.-Define-Purpose"><a class="docs-heading-anchor" href="#3.-Define-Purpose">3. Define Purpose</a><a id="3.-Define-Purpose-1"></a><a class="docs-heading-anchor-permalink" href="#3.-Define-Purpose" title="Permalink"></a></h3><p>Add a purpose function for your metric type:</p><pre><code class="language-julia hljs">import OmniTools: purpose

purpose(::Type{NewMetric}) = &quot;Description of what NewMetric does&quot;</code></pre><h3 id="4.-Testing"><a class="docs-heading-anchor" href="#4.-Testing">4. Testing</a><a id="4.-Testing-1"></a><a class="docs-heading-anchor-permalink" href="#4.-Testing" title="Permalink"></a></h3><p>Test your new metric by:</p><ul><li>Running it on sample data</li><li>Comparing results with existing metrics</li><li>Verifying it works correctly with different data types and sizes</li><li>Testing edge cases (e.g., NaN values)</li></ul><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><h3 id="Calculating-Metrics"><a class="docs-heading-anchor" href="#Calculating-Metrics">Calculating Metrics</a><a id="Calculating-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Calculating-Metrics" title="Permalink"></a></h3><pre><code class="language-julia hljs">using ErrorMetrics

# Define observations and model output
y = [1.0, 2.0, 3.0]  # observations
yσ = [0.1, 0.1, 0.1]  # uncertainties
ŷ = [1.1, 2.1, 3.1]  # model output

# Calculate MSE
mse = metric(MSE(), ŷ, y, yσ)

# Calculate correlation
correlation = metric(Pcor(), ŷ, y, yσ)

# Calculate NSE with uncertainty
nse_uncertain = metric(NSEσ(), ŷ, y, yσ)</code></pre><h3 id="Using-Multiple-Metrics"><a class="docs-heading-anchor" href="#Using-Multiple-Metrics">Using Multiple Metrics</a><a id="Using-Multiple-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Using-Multiple-Metrics" title="Permalink"></a></h3><pre><code class="language-julia hljs">using ErrorMetrics

# Calculate multiple metrics for comparison
metrics = Dict(
    :mse =&gt; metric(MSE(), ŷ, y, yσ),
    :nse =&gt; metric(NSE(), ŷ, y, yσ),
    :pcor =&gt; metric(Pcor(), ŷ, y, yσ),
    :scor =&gt; metric(Scor(), ŷ, y, yσ)
)</code></pre><h2 id="Best-Practices"><a class="docs-heading-anchor" href="#Best-Practices">Best Practices</a><a id="Best-Practices-1"></a><a class="docs-heading-anchor-permalink" href="#Best-Practices" title="Permalink"></a></h2><ol><li><p><strong>Documentation</strong></p><ul><li>Add clear documentation for your new metric</li><li>Include mathematical formulas if applicable</li><li>Provide usage examples</li></ul></li><li><p><strong>Testing</strong></p><ul><li>Test with various data types and sizes</li><li>Verify edge cases (e.g., NaN values)</li><li>Compare with existing metrics</li></ul></li><li><p><strong>Performance</strong></p><ul><li>Optimize for large datasets</li><li>Consider memory usage</li><li>Handle missing values appropriately</li></ul></li><li><p><strong>Compatibility</strong></p><ul><li>Ensure compatibility with existing workflows</li><li>Follow the established interface</li><li>Maintain consistent error handling</li></ul></li></ol><h2 id="Defining-Purpose-for-Metric-Types"><a class="docs-heading-anchor" href="#Defining-Purpose-for-Metric-Types">Defining Purpose for Metric Types</a><a id="Defining-Purpose-for-Metric-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-Purpose-for-Metric-Types" title="Permalink"></a></h2><p>Each metric type in ErrorMetrics.jl should have a <code>purpose</code> function that describes its role. This helps with documentation and provides clear information about what each metric does.</p><h3 id="How-to-Define-Purpose"><a class="docs-heading-anchor" href="#How-to-Define-Purpose">How to Define Purpose</a><a id="How-to-Define-Purpose-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-Define-Purpose" title="Permalink"></a></h3><ol><li>Make sure that the base <code>purpose</code> function from OmniTools is already imported:</li></ol><pre><code class="language-julia hljs">import OmniTools: purpose</code></pre><ol><li>Then, <code>purpose</code> can be easily extended for your metric type:</li></ol><pre><code class="language-julia hljs"># For a concrete metric type
purpose(::Type{MyMetric}) = &quot;Description of what MyMetric does&quot;</code></pre><h3 id="Best-Practices-2"><a class="docs-heading-anchor" href="#Best-Practices-2">Best Practices</a><a class="docs-heading-anchor-permalink" href="#Best-Practices-2" title="Permalink"></a></h3><ul><li>Keep descriptions concise but informative</li><li>Focus on what the metric measures and how it&#39;s calculated</li><li>Include any normalization or scaling factors in the description</li><li>For abstract types, clearly indicate their role in the type hierarchy</li></ul></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="types/">Types »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 18 December 2025 14:18">Thursday 18 December 2025</span>. Using Julia version 1.12.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
